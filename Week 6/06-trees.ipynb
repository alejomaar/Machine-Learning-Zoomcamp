{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "The goal of this homework is to create a regression model for predicting housing prices (column 'median_house_value').  \n",
    "\n",
    "In this homework we'll again use the California Housing Prices dataset - the same one we used in homework 2 and 3.\n",
    "\n",
    "You can take it from [Kaggle](https://www.kaggle.com/datasets/camnugent/california-housing-prices) or download using wget link mentioned below:\n",
    "\n",
    "```\n",
    "wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\user\\anaconda3\\envs\\ml-zoomcamp\\lib\\site-packages (3.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved under housing.csv\n"
     ]
    }
   ],
   "source": [
    "!python -m wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@ IMPORTING LIBRARIES AND DEPENDENCIES:\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "#from tqdm.auto import tqdm\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "Use only the following columns:  \n",
    "* `'latitude'`,\n",
    "* `'longitude'`,\n",
    "* `'housing_median_age'`,\n",
    "* `'total_rooms'`,\n",
    "* `'total_bedrooms'`,\n",
    "* `'population'`,\n",
    "* `'households'`,\n",
    "* `'median_income'`,\n",
    "* `'median_house_value'`,\n",
    "* `'ocean_proximity'`  \n",
    "\n",
    "* Fill NAs with 0.\n",
    "* Apply the log tranform to `median_house_value`.\n",
    "* Do train/validation/test split with 60%/20%/20% distribution. \n",
    "* Use the `train_test_split` function and set the `random_state` parameter to 1.\n",
    "* Use `DictVectorizer` to turn the dataframe into matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_cols = [\"longitude\", \"latitude\", \"housing_median_age\", \"total_rooms\", \"total_bedrooms\", \"population\", \"households\", \n",
    "               \"median_income\", \"median_house_value\", \"ocean_proximity\"]\n",
    "df = pd.read_csv('housing.csv', usecols=select_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude               0\n",
       "latitude                0\n",
       "housing_median_age      0\n",
       "total_rooms             0\n",
       "total_bedrooms        207\n",
       "population              0\n",
       "households              0\n",
       "median_income           0\n",
       "median_house_value      0\n",
       "ocean_proximity         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill N/A with 0\n",
    "df.total_bedrooms = df.total_bedrooms.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>20640.0</td>\n",
       "      <td>20640.0</td>\n",
       "      <td>20640.0</td>\n",
       "      <td>20640.0</td>\n",
       "      <td>20640.0</td>\n",
       "      <td>20640.0</td>\n",
       "      <td>20640.0</td>\n",
       "      <td>20640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-120.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2636.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>1425.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>206856.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2182.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>115396.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-122.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1448.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>787.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>119600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2127.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>1166.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>179700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3148.0</td>\n",
       "      <td>643.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>264725.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>39320.0</td>\n",
       "      <td>6445.0</td>\n",
       "      <td>35682.0</td>\n",
       "      <td>6082.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>500001.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "count    20640.0   20640.0             20640.0      20640.0         20640.0   \n",
       "mean      -120.0      36.0                29.0       2636.0           532.0   \n",
       "std          2.0       2.0                13.0       2182.0           423.0   \n",
       "min       -124.0      33.0                 1.0          2.0             0.0   \n",
       "25%       -122.0      34.0                18.0       1448.0           292.0   \n",
       "50%       -118.0      34.0                29.0       2127.0           431.0   \n",
       "75%       -118.0      38.0                37.0       3148.0           643.0   \n",
       "max       -114.0      42.0                52.0      39320.0          6445.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "count     20640.0     20640.0        20640.0             20640.0  \n",
       "mean       1425.0       500.0            4.0            206856.0  \n",
       "std        1132.0       382.0            2.0            115396.0  \n",
       "min           3.0         1.0            0.0             14999.0  \n",
       "25%         787.0       280.0            3.0            119600.0  \n",
       "50%        1166.0       409.0            4.0            179700.0  \n",
       "75%        1725.0       605.0            5.0            264725.0  \n",
       "max       35682.0      6082.0           15.0            500001.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply log transform\n",
    "df[\"median_house_value\"] = np.log1p(df[\"median_house_value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12384, 4128, 4128)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train),len(df_test), len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.median_house_value.values\n",
    "y_val = df_val.median_house_value.values\n",
    "y_test = df_test.median_house_value.values\n",
    "\n",
    "del df_train['median_house_value']\n",
    "del df_val['median_house_value']\n",
    "del df_test['median_house_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply DictVectorizer for OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12384, 14)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "train_dicts = df_train.to_dict(orient='records')\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train = dv.fit_transform(train_dicts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Let's train a decision tree regressor to predict the `median_house_value` variable. \n",
    "\n",
    "* Train a model with `max_depth=1`.\n",
    "\n",
    "\n",
    "Which feature is used for splitting the data?\n",
    "\n",
    "* `ocean_proximity=INLAND`\n",
    "* `total_rooms`\n",
    "* `latitude`\n",
    "* `population`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-fb48df5506b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml-zoomcamp\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    967\u001b[0m         \"\"\"\n\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    970\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml-zoomcamp\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_classification\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m             \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml-zoomcamp\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;34m\"multilabel-sequences\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     ]:\n\u001b[1;32m--> 200\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 578.  ,   19.  ,   34.63, ..., 1677.  ,  606.  , 3562.  ],\n",
       "       [  50.  ,   10.  ,   34.69, ...,  108.  ,  102.  ,  337.  ],\n",
       "       [ 462.  ,   27.  ,   33.78, ..., 1723.  ,  491.  , 1672.  ],\n",
       "       ...,\n",
       "       [ 854.  ,   18.  ,   33.9 , ..., 2276.  ,  922.  , 3380.  ],\n",
       "       [ 415.  ,   41.  ,   36.78, ..., 1129.  ,  462.  , 2227.  ],\n",
       "       [ 589.  ,    9.  ,   34.02, ..., 2280.  ,  587.  , 4265.  ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml-zoomcamp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "181881a0b307ca682e4a224e0e0b9985c4687fb0d86dc7fa4c6974d183122977"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
